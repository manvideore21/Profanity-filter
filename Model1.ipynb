{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "123dd656-9f8f-4216-a94a-edb1021e8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d408fe2-bea4-4494-9192-1283d0b3af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DataProfanity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3df3899-3221-4f5d-9568-5817fd623db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocessed_text    3322\n",
       "toxicity             3322\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bbc7854-cb12-4485-a741-e002e6116603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@55</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ssfcker</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ssfucker</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ssfvcker</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preprocessed_text  toxicity\n",
       "0                69       1.0\n",
       "1               @55       1.0\n",
       "2          @ssfcker       2.8\n",
       "3         @ssfucker       2.8\n",
       "4         @ssfvcker       2.4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86900928-107d-495c-920b-119d631aeba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03b7919f-9d71-4e92-8820-75c914e67b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_text    3322\n",
      "toxicity               11\n",
      "dtype: int64\n",
      "Total number of unique words in all columns: 3333\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df.apply(lambda x: x.nunique())\n",
    "print(unique_counts)\n",
    "total_unique_words = unique_counts.sum()\n",
    "print(\"Total number of unique words in all columns:\", total_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae052b62-3b78-4182-a8f7-a280e66fa0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.043347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.529229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          toxicity\n",
       "count  3322.000000\n",
       "mean      2.043347\n",
       "std       0.529229\n",
       "min       1.000000\n",
       "25%       1.800000\n",
       "50%       2.000000\n",
       "75%       2.400000\n",
       "max       3.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f2e86cb-d447-492d-a69d-0b1339e32234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>nudes</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>she male</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>shibary</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>three some</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>yury</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     preprocessed_text  toxicity\n",
       "3317             nudes       2.0\n",
       "3318          she male       2.0\n",
       "3319           shibary       2.0\n",
       "3320        three some       2.0\n",
       "3321              yury       2.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ab1625d-7eae-4e00-8050-47c69c189cbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Profanity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Profanity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Iterate through the Profanity column\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProfanity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Check if Canonical Form 1 exists\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanonical Form 1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     10\u001b[0m         canonical_form_1_values \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfanity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m value][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanonical Form 1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Profanity'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store unique profanity words and severity ratings\n",
    "data = []\n",
    "\n",
    "# Iterate through the Profanity column\n",
    "for value in df['Profanity']:\n",
    "    # Check if Canonical Form 1 exists\n",
    "    if 'Canonical Form 1' in df.columns:\n",
    "        canonical_form_1_values = df[df['Profanity'] == value]['Canonical Form 1'].dropna().unique()\n",
    "        for cf1_value in canonical_form_1_values:\n",
    "            if ':' in cf1_value:\n",
    "                profanity_word, severity_rating = cf1_value.split(':')\n",
    "            else:\n",
    "                profanity_word = cf1_value.strip()\n",
    "                severity_rating = str(df[df['Profanity'] == value]['Severity Rating'].iloc[0])  # Convert to string\n",
    "            # Convert severity_rating to integer, handling non-numeric characters\n",
    "            severity_rating = ''.join(filter(str.isdigit, severity_rating))\n",
    "            data.append({'Profanity': profanity_word.strip(), 'Severity Rating': int(severity_rating.strip())})\n",
    "\n",
    "    # Check if Canonical Form 2 exists\n",
    "    if 'Canonical Form 2' in df.columns:\n",
    "        canonical_form_2_values = df[df['Profanity'] == value]['Canonical Form 2'].dropna().unique()\n",
    "        for cf2_value in canonical_form_2_values:\n",
    "            if ':' in cf2_value:\n",
    "                profanity_word, severity_rating = cf2_value.split(':')\n",
    "            else:\n",
    "                profanity_word = cf2_value.strip()\n",
    "                severity_rating = str(df[df['Profanity'] == value]['Severity Rating'].iloc[0])  # Convert to string\n",
    "            # Convert severity_rating to integer, handling non-numeric characters\n",
    "            severity_rating = ''.join(filter(str.isdigit, severity_rating))\n",
    "            data.append({'Profanity': profanity_word.strip(), 'Severity Rating': int(severity_rating.strip())})\n",
    "\n",
    "    # Check if Canonical Form 3 exists\n",
    "    if 'Canonical Form 3' in df.columns:\n",
    "        canonical_form_3_values = df[df['Profanity'] == value]['Canonical Form 3'].dropna().unique()\n",
    "        for cf3_value in canonical_form_3_values:\n",
    "            if ':' in cf3_value:\n",
    "                profanity_word, severity_rating = cf3_value.split(':')\n",
    "            else:\n",
    "                profanity_word = cf3_value.strip()\n",
    "                severity_rating = str(df[df['Profanity'] == value]['Severity Rating'].iloc[0])  # Convert to string\n",
    "            # Convert severity_rating to integer, handling non-numeric characters\n",
    "            severity_rating = ''.join(filter(str.isdigit, severity_rating))\n",
    "            data.append({'Profanity': profanity_word.strip(), 'Severity Rating': int(severity_rating.strip())})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "new_df = pd.DataFrame(data)\n",
    "\n",
    "# Drop duplicate rows if any\n",
    "new_df = new_df.drop_duplicates()\n",
    "\n",
    "# Reset the index of the new DataFrame\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88dbf506-de6e-4946-b4f1-42cb64db1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ebe3c9e-34ac-4b74-ab8b-07fd35fda6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profanity</th>\n",
       "      <th>Severity Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>towelhead</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ass</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nigger</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wetback</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spic</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Profanity  Severity Rating\n",
       "0  towelhead               30\n",
       "1        ass               30\n",
       "2     nigger               30\n",
       "3    wetback               30\n",
       "4       spic               30"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30cfb6c2-7820-40c7-b1f0-fced85163582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wound', 'penis', 'queer', 'rectum', 'ramrod', 'man chowder', 'motherfucker', 'choad', 'whack off', 'wank', 'trash', 'redskin', 'cholo', 'porch monkey', 'bang', 'pig', 'nymph', 'fuck', 'ass', 'twat', 'twink', 'nigger', 'gowl', 'pecker', 'jailbait', 'coon', 'dump a load', 'foreskin', 'garbage bag', 'kike', 'dick', 'grope', 'blowjob', 'shlong', 'schlong', 'bastard', 'jiggaboo', 'upskirt', 'spunk', 'transvestite', 'throater', 'klan', 'butt', 'pole sucker', 'ape', 'tit', 'doggy style', 'faggot', 'reacharound', 'peter puffer', 'pull the pud', 'tits', 'slit', 'blacky', 'hooters', 'piss', 'cum', 'meat', 'taking the piss', 'throat yogurt', 'hoe', 'pole smoker', 'douche', 'breast', 'ballsack', 'cock', 'spank', 'salad tosser', 'blow a load', 'dolt', 'funbags', 'anus', 'slant eye', 'mongoloid', 'nipple', 'injun', 'weiner', 'fudge packer', 'fellatio', 'ejaculation', 'hell', 'nigga', 'double pen', 'sphincter', 'bonk', 'scum', 'tickle the pickle', 'tossing salad', 'clit', 'monkey', 'abraham', 'shemale', 'towelhead', 'chink', 'dirty sanchez', 'cunnilingus', 'retarded', 'dildo', 'flamer', 'punta', 'snatch', 'masturbate', 'palm jockey', 'spic', 'slag', 'vulva', 'dipstick', 'tadger', 'tacohead', 'mongrel', 'man seed', 'oven dodger', 'cojones', 'bollocks', 'niggers', 'dyke', 'bender', 'wetback', 'diddle', 'wang', 'lesbian', 'hag', 'willy-whacker', 'dago', 'kitty puncher', 'shylock', 'pancake face', 'kkk', 'homosexual', 'prick', 'groid', 'jerk', 'turd', 'dong', 'crow', 'sadomasochism', 'damn', 'whore', 'darky', 'nut butter', 'beaner', 'jim crow', 'girly bits', 'tallywacker', 'ku kluxer', 'raghead', 'bellend', 'china virus', 'muff', 'mushroom tip', 'pillow biter', 'spook', 'scut', 'polesmoker', 'window licker', 'punani', 'loose', 'jap', 'slut', 'tosser', 'bitch', 'sissy', '69', 'paki', 'buttermilk', 'cooties', 'boiolas', 'testicles', 'knob', 'chocha', 'jew', 'meat curtains', 'suck', 'abeed', 'tramp', 'gash-stabber', 'gin jockey', 'arse', 'jackoff', 'bum', 'molest', 'bondage', 'jizz', 'gay', 'rim job', 'pussy', 'sperm', 'sex', 'swine', 'tranny', 'greaser', 'hustler', 'tar-baby', 'baby batter', 'boner', 'shiester', 'fart', 'jerk off', 'mong', 'kidtoucher', 'stump chewer', 'shit', 'skank', 'abo', 'finger', 'tart', 'vagina', 'fag', 'coolie', 'negro', 'camel jockey', 'sausage jockey', 'creampie', 'milf', 'chingchong', 'gypsy', 'erectoplasm', 'gook', 'nonce', 'cameltoe', 'cotton picker', 'bung', 'sambo', 'pole licker', 'pedophile', 'cunt', 'zipperhead', 'harry palms', 'girlyboy', 'ladyboy', 'trouser snake', 'anal', 'hebe', 'wop', 'dothead', 'jack off', 'retard', 'carpet muncher', 'crotch', 'boobs', 'choke the chicken', 'niggger', 'coot', 'blumpkin', 'nutsack', 'weenie', 'bean queen', 'booty', 'bugger', 'beat off', 'trousersnake', 'orgasm']\n"
     ]
    }
   ],
   "source": [
    "profanity_words = []\n",
    "for column in new_df.columns:\n",
    "    if column != 'Severity Rating':\n",
    "        profanity_words.extend(new_df[column].dropna().unique())\n",
    "profanity_words = list(set(profanity_words))\n",
    "print(profanity_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca7cc813-0899-442e-b234-2f9c262e8a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(profanity_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3f2da-5eeb-41a8-bb05-d139894c044a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b187045-d6b7-4a23-b33d-55ac7a2b6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize profanity words\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "profanity_vectors = tfidf_vectorizer.fit_transform(profanity_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c3a84cd-7574-4490-b394-6f9092230a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_profanity(sentence):\n",
    "    sentence_tokens = sentence.split()\n",
    "    severity_rating = 0\n",
    "    profanity_count = 0\n",
    "    max_severity_rating = 0\n",
    "    for word in sentence_tokens:\n",
    "        word_vector = tfidf_vectorizer.transform([word])\n",
    "        similarity_scores = cosine_similarity(word_vector, profanity_vectors)\n",
    "        max_similarity_score = np.max(similarity_scores)\n",
    "        if max_similarity_score > 0.8:  # Adjust threshold\n",
    "            profanity_count += 1\n",
    "            profanity_word_index = np.argmax(similarity_scores)\n",
    "            severity_rating += new_df.loc[profanity_word_index, 'Severity Rating']\n",
    "            max_severity_rating = max(max_severity_rating, new_df.loc[profanity_word_index, 'Severity Rating'])\n",
    "    \n",
    "    # Increase severity if multiple profanities are found\n",
    "    if profanity_count > 1:\n",
    "        severity_rating += max_severity_rating * (profanity_count - 1)\n",
    "    \n",
    "    # Cap severity rating at 3\n",
    "    severity_rating = min(severity_rating, 3)\n",
    "    \n",
    "    return severity_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7dafa5f-849f-4f9a-b51a-1cc7b0a9b9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence does not contain profanity.\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "input_sentence = \"black bi\"\n",
    "severity_rating = detect_profanity(input_sentence)\n",
    "if severity_rating > 0:\n",
    "    print(\"Severity Rating:\", severity_rating)\n",
    "else:\n",
    "    print(\"The sentence does not contain profanity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af83e01-6d35-4c3d-b1d7-71e075f84762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681237902243493\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"black man\"\n",
    "word_vector = tfidf_vectorizer.transform([input_sentence])\n",
    "similarity_scores = cosine_similarity(word_vector, profanity_vectors)\n",
    "max_similarity_score = np.max(similarity_scores)\n",
    "print(max_similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1121bab0-6207-4b2c-9519-e25e7a3759bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"black man\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f315a019-cef1-4d37-b95f-364cd494cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'man']\n"
     ]
    }
   ],
   "source": [
    "# Split the string into a list of words\n",
    "word_list = sentence.split()\n",
    "\n",
    "# Print the resulting list\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3c5e73-0248-49bd-b265-2be056d01d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'black' does not contain profanity.\n",
      "Word 'man' does not contain profanity.\n"
     ]
    }
   ],
   "source": [
    "for word in word_list:\n",
    "    severity_rating = detect_profanity(word)\n",
    "    rating = str(severity_rating)\n",
    "    if severity_rating > 0:\n",
    "        print(f\"Word '{word}' has profanity. Severity Rating:\", rating)\n",
    "    else:\n",
    "        print(f\"Word '{word}' does not contain profanity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1527658-6946-47f2-8aca-620d4f4a891c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b651ec-ab4d-4d0a-a3a1-a01e06b341a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f79e1-8e24-4246-b3b5-a1279936f6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
